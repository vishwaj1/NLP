{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMFr0ImTfbkV",
        "outputId": "71174321-cb3d-4594-8aa0-e973c0074862"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PbsrmACwenTb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from conllu import parse_incr\n",
        "\n",
        "def load_data(file_path):\n",
        "    sentences = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for tokenlist in parse_incr(file):\n",
        "            words = [token['form'] for token in tokenlist]\n",
        "            pos_tags = [token['upostag'] for token in tokenlist]\n",
        "            heads = [token['head'] for token in tokenlist]\n",
        "            labels = [token['deprel'] for token in tokenlist]\n",
        "            sentences.append((words, pos_tags, heads, labels))\n",
        "    return sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data):\n",
        "    words = set()\n",
        "    pos_tags = set()\n",
        "    labels = set()\n",
        "    for sentence in data:\n",
        "        words.update(sentence[0])\n",
        "        pos_tags.update(sentence[1])\n",
        "        labels.update(sentence[3])\n",
        "    word2idx = {word: i + 1 for i, word in enumerate(words)}  # +1 to start index from 1\n",
        "    word2idx['<UNK>'] = 0  # Unknown words\n",
        "    pos2idx = {tag: i + 1 for i, tag in enumerate(pos_tags)}  # +1 to start index from 1\n",
        "    pos2idx['<UNK>'] = 0  # Unknown POS tags\n",
        "    label2idx = {label: i for i, label in enumerate(labels)}\n",
        "    return word2idx, pos2idx, label2idx\n",
        "\n",
        "# Load data\n",
        "dev_data = load_data('dev.gold.conll')\n",
        "train_data = load_data('train.gold.conll')\n",
        "\n",
        "# Build vocabularies\n",
        "word2idx, pos2idx, label2idx = build_vocab(train_data)\n"
      ],
      "metadata": {
        "id": "K00kesKhgoT-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class DependencyParsingDataset(Dataset):\n",
        "    def __init__(self, data, word2idx, pos2idx, label2idx):\n",
        "        self.data = data\n",
        "        self.word2idx = word2idx\n",
        "        self.pos2idx = pos2idx\n",
        "        self.label2idx = label2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words, pos_tags, heads, labels = self.data[idx]\n",
        "        word_idxs = [self.word2idx.get(word.lower(), self.word2idx['<UNK>']) for word in words]\n",
        "        pos_idxs = [self.pos2idx.get(pos, self.pos2idx['<UNK>']) for pos in pos_tags]\n",
        "        head_idxs = [int(head) for head in heads]  # Ensure head indices are integers\n",
        "        label_idxs = [self.label2idx[label] for label in labels]\n",
        "        return torch.tensor(word_idxs, dtype=torch.long), \\\n",
        "               torch.tensor(pos_idxs, dtype=torch.long), \\\n",
        "               torch.tensor(head_idxs, dtype=torch.long), \\\n",
        "               torch.tensor(label_idxs, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    word_idxs, pos_idxs, head_idxs, label_idxs = zip(*batch)\n",
        "    word_idxs = pad_sequence(word_idxs, batch_first=True, padding_value=0)\n",
        "    pos_idxs = pad_sequence(pos_idxs, batch_first=True, padding_value=0)\n",
        "    head_idxs = pad_sequence(head_idxs, batch_first=True, padding_value=0)\n",
        "    label_idxs = pad_sequence(label_idxs, batch_first=True, padding_value=0)\n",
        "    return word_idxs, pos_idxs, head_idxs, label_idxs\n"
      ],
      "metadata": {
        "id": "4ZmMy_0_euvu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DependencyParser(nn.Module):\n",
        "    def __init__(self, vocab_size, pos_size, num_labels, embedding_dim, hidden_dim):\n",
        "        super(DependencyParser, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_embeddings = nn.Embedding(pos_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim * 2, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.heads_linear = nn.Linear(hidden_dim * 2, vocab_size)  # Predicting heads\n",
        "        self.labels_linear = nn.Linear(hidden_dim * 2, num_labels)  # Predicting labels\n",
        "\n",
        "    def forward(self, word_idxs, pos_idxs):\n",
        "        word_embeds = self.word_embeddings(word_idxs)\n",
        "        pos_embeds = self.pos_embeddings(pos_idxs)\n",
        "        embeddings = torch.cat((word_embeds, pos_embeds), dim=2)\n",
        "        lstm_out, _ = self.lstm(embeddings)\n",
        "        head_space = self.heads_linear(lstm_out)\n",
        "        label_space = self.labels_linear(lstm_out)\n",
        "        return head_space, label_space\n"
      ],
      "metadata": {
        "id": "7DUtW5dQxQmq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_model(model, dataset, epochs, learning_rate):\n",
        "    data_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    head_loss_function = nn.CrossEntropyLoss(ignore_index=0)  # Assuming padding index is 0\n",
        "    label_loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for word_idxs, pos_idxs, head_idxs, label_idxs in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            head_outputs, label_outputs = model(word_idxs, pos_idxs)\n",
        "            loss_heads = head_loss_function(head_outputs.transpose(1, 2), head_idxs)\n",
        "            loss_labels = label_loss_function(label_outputs.transpose(1, 2), label_idxs)\n",
        "            loss = loss_heads + loss_labels\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss / len(data_loader)}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "dataset = DependencyParsingDataset(train_data, word2idx, pos2idx, label2idx)\n",
        "model = DependencyParser(len(word2idx), len(pos2idx), len(label2idx), 100, 200)\n",
        "train_model(model, dataset, 1, 0.01)\n"
      ],
      "metadata": {
        "id": "pXNx6MYzew8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataset, device=torch.device('cpu')):\n",
        "    model.eval()\n",
        "    total_tokens = 0\n",
        "    correct_heads = 0\n",
        "    with torch.no_grad():\n",
        "        for word_idxs, pos_idxs, head_idxs, label_idxs in DataLoader(dataset, batch_size=1, collate_fn=collate_fn):\n",
        "            word_idxs, pos_idxs = word_idxs.to(device), pos_idxs.to(device)\n",
        "            head_outputs, label_outputs = model(word_idxs, pos_idxs)\n",
        "            _, predicted_heads = torch.max(head_outputs, dim=2)\n",
        "            correct_heads += (predicted_heads == head_idxs.to(device)).sum().item()\n",
        "            total_tokens += head_idxs.numel()\n",
        "    uas = correct_heads / total_tokens\n",
        "    return uas\n"
      ],
      "metadata": {
        "id": "Kv8sj0XX9qV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# def evaluate(model, dataset, device=torch.device('cpu')):\n",
        "#     model.eval()  # Set the model to evaluation mode\n",
        "#     model.to(device)\n",
        "\n",
        "#     all_true_heads = []\n",
        "#     all_pred_heads = []\n",
        "#     all_true_labels = []\n",
        "#     all_pred_labels = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for word_idxs, pos_idxs, head_idxs, label_idxs in DataLoader(dataset, batch_size=1, collate_fn=collate_fn):\n",
        "#             word_idxs, pos_idxs, head_idxs, label_idxs = word_idxs.to(device), pos_idxs.to(device), head_idxs.to(device), label_idxs.to(device)\n",
        "#             outputs = model(word_idxs, pos_idxs)\n",
        "#             _, predicted_heads = torch.max(outputs, dim=2)  # Assuming outputs are logits for each head position\n",
        "#             predicted_labels = predicted_heads  # Adjust if your model also predicts labels differently\n",
        "\n",
        "#             # Flatten the tensors for metric calculation\n",
        "#             all_true_heads.extend(head_idxs.view(-1).cpu().numpy())\n",
        "#             all_pred_heads.extend(predicted_heads.view(-1).cpu().numpy())\n",
        "#             all_true_labels.extend(label_idxs.view(-1).cpu().numpy())\n",
        "#             all_pred_labels.extend(predicted_labels.view(-1).cpu().numpy())\n",
        "\n",
        "#     uas = accuracy_score(all_true_heads, all_pred_heads)\n",
        "#     las = accuracy_score(all_true_labels, all_pred_labels)\n",
        "#     precision = precision_score(all_true_labels, all_pred_labels, average='micro')\n",
        "#     recall = recall_score(all_true_labels, all_pred_labels, average='micro')\n",
        "#     f1 = f1_score(all_true_labels, all_pred_labels, average='micro')\n",
        "\n",
        "#     return uas, las, precision, recall, f1\n",
        "\n"
      ],
      "metadata": {
        "id": "5NIZh-Jxnd87"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# def evaluate(model, dataset, device=torch.device('cpu')):\n",
        "#     model.eval()\n",
        "#     all_true_heads = []\n",
        "#     all_pred_heads = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for word_idxs, pos_idxs, head_idxs, label_idxs in DataLoader(dataset, batch_size=1, collate_fn=collate_fn):\n",
        "#             outputs = model(word_idxs.to(device), pos_idxs.to(device))\n",
        "#             _, predicted_heads = torch.max(outputs, dim=2)\n",
        "#             all_true_heads.extend(head_idxs.view(-1).cpu().numpy())\n",
        "#             all_pred_heads.extend(predicted_heads.view(-1).cpu().numpy())\n",
        "\n",
        "#     uas = accuracy_score(all_true_heads, all_pred_heads)  # Simple accuracy for heads\n",
        "#     return uas\n"
      ],
      "metadata": {
        "id": "68NhT0-INf0u"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = load_data('test.gold.conll')\n",
        "test_dataset = DependencyParsingDataset(test_data, word2idx, pos2idx, label2idx)\n",
        "\n",
        "uas, las, precision, recall, f1 = evaluate(model, test_dataset)\n",
        "print(f\"UAS: {uas*100:.2f}%\")\n",
        "print(f\"LAS: {las*100:.2f}%\")\n",
        "print(f\"Precision: {precision*100:.2f}%\")\n",
        "print(f\"Recall: {recall*100:.2f}%\")\n",
        "print(f\"F1 Score: {f1*100:.2f}%\")\n",
        "\n",
        "dev_dataset = DependencyParsingDataset(dev_data, word2idx, pos2idx, label2idx)\n",
        "uas, las, precision, recall, f1 = evaluate(model, dev_dataset)\n",
        "print(f\"UAS: {uas*100:.2f}%\")\n",
        "print(f\"LAS: {las*100:.2f}%\")\n",
        "print(f\"Precision: {precision*100:.2f}%\")\n",
        "print(f\"Recall: {recall*100:.2f}%\")\n",
        "print(f\"F1 Score: {f1*100:.2f}%\")\n",
        "\n",
        "# uas = evaluate(model,test_dataset)\n",
        "# print(f\"UAS: {uas*100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jOLCVPxWne3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf29423-ade0-4d20-9e5b-f4b1dfea8275"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UAS: 2.37%\n",
            "LAS: 94.63%\n",
            "Precision: 94.63%\n",
            "Recall: 94.63%\n",
            "F1 Score: 94.63%\n",
            "UAS: 2.46%\n",
            "LAS: 94.38%\n",
            "Precision: 94.38%\n",
            "Recall: 94.38%\n",
            "F1 Score: 94.38%\n"
          ]
        }
      ]
    }
  ]
}